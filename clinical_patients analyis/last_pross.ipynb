{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b393ff-162f-433d-bdcb-84398a36c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['patient_id', 'site_id', 'site_name', 'country', 'city', 'age', 'gender', 'ethnicity', 'screening_date', 'enrollment_date', 'randomization_date', 'dropout_date', 'dropout_reason', 'has_diabetes', 'has_hypertension', 'has_heart_disease', 'weight_kg', 'height_cm', 'bmi', 'systolic_bp', 'diastolic_bp', 'hemoglobin_gdl', 'creatinine_mgdl', 'glucose_mgdl', 'visit_completion_rate', 'missed_visits', 'medication_adherence', 'data_quality_score', 'age_group']\n",
      "Missing values after cleaning:\n",
      "dropout_date             1505\n",
      "dropout_reason           1504\n",
      "randomization_date        635\n",
      "enrollment_date           436\n",
      "creatinine_mgdl           275\n",
      "hemoglobin_gdl            231\n",
      "glucose_mgdl              213\n",
      "systolic_bp               184\n",
      "diastolic_bp              184\n",
      "medication_adherence      181\n",
      "visit_completion_rate     153\n",
      "weight_kg                 120\n",
      "height_cm                 106\n",
      "city                       30\n",
      "gender                      0\n",
      "ethnicity                   0\n",
      "screening_date              0\n",
      "patient_id                  0\n",
      "site_id                     0\n",
      "site_name                   0\n",
      "country                     0\n",
      "age                         0\n",
      "has_diabetes                0\n",
      "has_hypertension            0\n",
      "has_heart_disease           0\n",
      "bmi                         0\n",
      "missed_visits               0\n",
      "data_quality_score          0\n",
      "age_group                   0\n",
      "dtype: int64\n",
      "Cleaned dataset shape: (1533, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abane\\AppData\\Local\\Temp\\ipykernel_16872\\1974130703.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_value, inplace=True)\n",
      "C:\\Users\\abane\\AppData\\Local\\Temp\\ipykernel_16872\\1974130703.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(mode_val[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('trail_dataset.csv')\n",
    "\n",
    "# Inspect columns for exact naming\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "# Convert date columns to datetime with correct names\n",
    "date_cols = ['screeningdate', 'enrollmentdate', 'randomizationdate', 'dropoutdate']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Convert boolean fields correctly (column names as per dataset)\n",
    "bool_cols = ['hasdiabetes', 'hashypertension', 'hasheartdisease']\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(bool)\n",
    "\n",
    "# Drop duplicates\n",
    "df_clean = df.drop_duplicates().copy()\n",
    "\n",
    "# Filter out age outliers (valid age range 18-85)\n",
    "if 'age' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['age'] >= 18) & (df_clean['age'] <= 85)]\n",
    "\n",
    "# Filter vital sign outliers (systolicbp 90-200, diastolicbp 60-120)\n",
    "if 'misystolicbp' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['misystolicbp'] >= 90) & (df_clean['misystolicbp'] <= 200)]\n",
    "if 'midiastolicbp' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['midiastolicbp'] >= 60) & (df_clean['midiastolicbp'] <= 120)]\n",
    "\n",
    "# Filter glucose outliers (70-300 mg/dL)\n",
    "if 'glucosemgdl' in df_clean.columns:\n",
    "    df_clean = df_clean[(df_clean['glucosemgdl'] >= 70) & (df_clean['glucosemgdl'] <= 300)]\n",
    "\n",
    "# Impute missing numerical values with median where numerical columns exist\n",
    "num_cols = ['weightkg', 'heightcm', 'bmi', 'misystolicbp', 'midiastolicbp', 'hemoglobingdl', 'creatininemgdl', 'glucosemgdl']\n",
    "for col in num_cols:\n",
    "    if col in df_clean.columns:\n",
    "        median_value = df_clean[col].median()\n",
    "        df_clean[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# Impute missing categorical values with mode\n",
    "cat_cols = ['gender', 'ethnicity', 'dropoutreason', 'country', 'siteid']\n",
    "for col in cat_cols:\n",
    "    if col in df_clean.columns:\n",
    "        mode_val = df_clean[col].mode()\n",
    "        if not mode_val.empty:\n",
    "            df_clean[col].fillna(mode_val[0], inplace=True)\n",
    "\n",
    "# Final check for missing values counts\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_clean.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Final cleaned shape\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Save cleaned dataset for further use\n",
    "df_clean.to_csv('trail_dataset2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cc1a3d-4bfe-4eb7-84a5-c2fe5dae8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      " patient_id                 0\n",
      "site_id                    0\n",
      "site_name                  0\n",
      "country                    0\n",
      "city                       0\n",
      "age                        0\n",
      "gender                     0\n",
      "ethnicity                  0\n",
      "screening_date             0\n",
      "enrollment_date          332\n",
      "randomization_date       500\n",
      "has_diabetes               0\n",
      "has_hypertension           0\n",
      "has_heart_disease          0\n",
      "weight_kg                  0\n",
      "height_cm                  0\n",
      "bmi                        0\n",
      "systolic_bp                0\n",
      "diastolic_bp               0\n",
      "hemoglobin_gdl           172\n",
      "creatinine_mgdl          209\n",
      "glucose_mgdl             169\n",
      "visit_completion_rate      0\n",
      "missed_visits              0\n",
      "medication_adherence       0\n",
      "data_quality_score         0\n",
      "age_group                  0\n",
      "dtype: int64\n",
      "Data cleaning complete. Cleaned dataset shape: (1180, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('trail_dataset3.csv')\n",
    "\n",
    "# Step 1: Convert dates to datetime dtype\n",
    "date_cols = ['screening_date', 'enrollment_date', 'randomization_date', 'dropout_date']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Step 2: Drop columns with >90% missing (dropout_date, dropout_reason)\n",
    "to_drop = []\n",
    "for col in ['dropout_date', 'dropout_reason']:\n",
    "    if col in df.columns:\n",
    "        missing_percent = df[col].isnull().mean() * 100\n",
    "        if missing_percent > 90:\n",
    "            to_drop.append(col)\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# Step 3: Convert booleans to bool dtype\n",
    "bool_cols = ['has_diabetes', 'has_hypertension', 'has_heart_disease']\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(bool)\n",
    "\n",
    "# Step 4: Remove duplicate records (if any)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 5: Filter age to valid range 18-85\n",
    "if 'age' in df.columns:\n",
    "    df = df[(df['age'] >= 18) & (df['age'] <= 85)]\n",
    "\n",
    "# Step 6: Fix invalid numeric outliers for vitals and labs\n",
    "# Blood pressure\n",
    "if 'systolic_bp' in df.columns:\n",
    "    df = df[(df['systolic_bp'] >= 90) & (df['systolic_bp'] <= 200)]\n",
    "if 'diastolic_bp' in df.columns:\n",
    "    df = df[(df['diastolic_bp'] >= 60) & (df['diastolic_bp'] <= 120)]\n",
    "\n",
    "# Glucose\n",
    "if 'glucose_mg_dl' in df.columns:\n",
    "    df = df[(df['glucose_mg_dl'] >= 70) & (df['glucose_mg_dl'] <= 300)]\n",
    "\n",
    "# Step 7: Impute missing numeric columns with median\n",
    "numeric_cols = [\n",
    "    'weight_kg', 'height_cm', 'bmi', 'systolic_bp', 'diastolic_bp',\n",
    "    'hemoglobin_g_dl', 'creatinine_mg_dl', 'glucose_mg_dl',\n",
    "    'medication_adherence', 'visit_completion_rate'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Step 8: Impute missing categorical columns with mode or 'Unknown'\n",
    "categorical_cols = ['gender', 'ethnicity', 'country', 'site_id', 'city']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        mode_val = df[col].mode()\n",
    "        if not mode_val.empty:\n",
    "            df[col] = df[col].fillna(mode_val[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Step 9: Recalculate BMI from height and weight for consistency\n",
    "if 'weight_kg' in df.columns and 'height_cm' in df.columns:\n",
    "    df['height_m'] = df['height_cm'] / 100\n",
    "    df['calculated_bmi'] = df['weight_kg'] / (df['height_m'] ** 2)\n",
    "\n",
    "    # Replace BMI if difference > 3 units\n",
    "    bmi_diff_mask = (df['bmi'] - df['calculated_bmi']).abs() > 3\n",
    "    df.loc[bmi_diff_mask, 'bmi'] = df.loc[bmi_diff_mask, 'calculated_bmi']\n",
    "\n",
    "    # Drop helper columns\n",
    "    df.drop(columns=['height_m', 'calculated_bmi'], inplace=True)\n",
    "\n",
    "# Step 10: Final check for missing data\n",
    "missing_final = df.isnull().sum()\n",
    "print(\"Missing values after cleaning:\\n\", missing_final)\n",
    "\n",
    "# Step 11: Save cleaned dataset\n",
    "df.to_csv('trail_dataset3_cleaned.csv', index=False)\n",
    "\n",
    "print(f\"Data cleaning complete. Cleaned dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0afc79-89ee-4d1e-8520-b1a816272384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "patient_id                 0\n",
      "site_id                    0\n",
      "site_name                  0\n",
      "country                    0\n",
      "city                       0\n",
      "age                        0\n",
      "gender                     0\n",
      "ethnicity                  0\n",
      "screening_date             0\n",
      "enrollment_date          332\n",
      "randomization_date       500\n",
      "has_diabetes               0\n",
      "has_hypertension           0\n",
      "has_heart_disease          0\n",
      "weight_kg                  0\n",
      "height_cm                  0\n",
      "bmi                        0\n",
      "systolic_bp                0\n",
      "diastolic_bp               0\n",
      "hemoglobin_gdl           172\n",
      "creatinine_mgdl          209\n",
      "glucose_mgdl             169\n",
      "visit_completion_rate      0\n",
      "missed_visits              0\n",
      "medication_adherence       0\n",
      "data_quality_score         0\n",
      "age_group                  0\n",
      "dtype: int64\n",
      "Data cleaning complete. Cleaned dataset shape: (1180, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('trail_dataset_3.csv')\n",
    "\n",
    "# Step 1: Convert date columns to datetime\n",
    "date_columns = ['screening_date', 'enrollment_date', 'randomization_date']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Step 2: Convert categorical columns to category dtype\n",
    "categorical_cols = ['gender', 'ethnicity', 'site_id', 'country', 'city']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Step 3: Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 4: Remove columns with more than 90% missing values\n",
    "threshold = 0.9\n",
    "cols_to_drop = [col for col in df.columns if df[col].isnull().mean() > threshold]\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Step 5: Impute missing numeric columns with median\n",
    "numeric_cols = ['weight_kg', 'height_cm', 'bmi', 'systolic_bp', 'diastolic_bp', \n",
    "                'hemoglobin_g_dl', 'creatinine_mg_dl', 'glucose_mg_dl', \n",
    "                'medication_adherence', 'visit_completion_rate']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Step 6: Impute missing categorical columns with mode or 'Unknown'\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        mode_val = df[col].mode()\n",
    "        fill_val = mode_val[0] if not mode_val.empty else 'Unknown'\n",
    "        df[col] = df[col].fillna(fill_val)\n",
    "\n",
    "# Step 7: Filter out invalid outliers in numeric data\n",
    "if 'age' in df.columns:\n",
    "    df = df[(df['age'] >= 18) & (df['age'] <= 85)]\n",
    "\n",
    "if 'systolic_bp' in df.columns:\n",
    "    df = df[(df['systolic_bp'] >= 90) & (df['systolic_bp'] <= 200)]\n",
    "\n",
    "if 'diastolic_bp' in df.columns:\n",
    "    df = df[(df['diastolic_bp'] >= 60) & (df['diastolic_bp'] <= 120)]\n",
    "\n",
    "if 'glucose_mg_dl' in df.columns:\n",
    "    df = df[(df['glucose_mg_dl'] >= 70) & (df['glucose_mg_dl'] <= 300)]\n",
    "\n",
    "# Step 8: Recalculate BMI from weight and height, adjust large differences\n",
    "if 'weight_kg' in df.columns and 'height_cm' in df.columns:\n",
    "    df['height_m'] = df['height_cm'] / 100\n",
    "    df['bmi_calc'] = df['weight_kg'] / (df['height_m'] ** 2)\n",
    "    bmi_diff_mask = (df['bmi'] - df['bmi_calc']).abs() > 3\n",
    "    df.loc[bmi_diff_mask, 'bmi'] = df.loc[bmi_diff_mask, 'bmi_calc']\n",
    "    df.drop(columns=['height_m', 'bmi_calc'], inplace=True)\n",
    "\n",
    "# Step 9: Final missing value check\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 10: Save cleaned dataset\n",
    "df.to_csv('trail_dataset_3_cleaned.csv', index=False)\n",
    "print(f\"Data cleaning complete. Cleaned dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be684af-8c67-4616-b443-a23c04375848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Ready for visualization.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('trail_dataset_41.csv')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df['enrollment_date'] = pd.to_datetime(df['enrollment_date'], errors='coerce')\n",
    "df['randomization_date'] = pd.to_datetime(df['randomization_date'], errors='coerce')\n",
    "\n",
    "# Handle missing values in date columns\n",
    "# Option 1: Keep nulls and visualize missingness\n",
    "# Option 2: Fill missing dates with a placeholder or imputed value\n",
    "# For example, filling with the earliest date in the dataset:\n",
    "# df['enrollment_date'].fillna(df['enrollment_date'].min(), inplace=True)\n",
    "# df['randomization_date'].fillna(df['randomization_date'].min(), inplace=True)\n",
    "\n",
    "# Example: Drop rows with missing date values if you prefer\n",
    "# df.dropna(subset=['enrollment_date', 'randomization_date'], inplace=True)\n",
    "\n",
    "# Save the preprocessed dataset if needed\n",
    "df.to_csv('preprocessed_trail_dataset.csv', index=False)\n",
    "\n",
    "print(\"Data preprocessing complete. Ready for visualization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31772e77-5e74-432d-999f-8d7f0a9d5183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DATA CLEANING PROCESS...\n",
      "Original dataset shape: (1180, 27)\n",
      "\n",
      "Step 1: Converting date columns to datetime...\n",
      "Converted screening_date to datetime\n",
      "Converted enrollment_date to datetime\n",
      "Converted randomization_date to datetime\n",
      "\n",
      "Step 2: Converting boolean columns...\n",
      "Converted has_diabetes to boolean\n",
      "Converted has_hypertension to boolean\n",
      "Converted has_heart_disease to boolean\n",
      "\n",
      "Step 3: Removing duplicates...\n",
      "Removed 0 duplicate rows\n",
      "\n",
      "Step 4: Handling missing values in numeric columns...\n",
      "Imputed 172 missing values in hemoglobin_gdl with median: 13.50\n",
      "Imputed 209 missing values in creatinine_mgdl with median: 1.13\n",
      "Imputed 169 missing values in glucose_mgdl with median: 109.30\n",
      "\n",
      "Step 5: Handling missing values in categorical columns...\n",
      "\n",
      "Step 6: Removing invalid outliers...\n",
      "Removed 3 rows with invalid outliers\n",
      "\n",
      "Step 7: Recalculating BMI for consistency...\n",
      "Fixed 0 inconsistent BMI values\n",
      "\n",
      "Step 8: Final data validation...\n",
      "Total missing values after cleaning: 828\n",
      "\n",
      "==================================================\n",
      "DATA CLEANING COMPLETED SUCCESSFULLY!\n",
      "==================================================\n",
      "Cleaned dataset shape: (1177, 27)\n",
      "Cleaned dataset saved as: trail_dataset_4_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# COMPLETE DATA CLEANING CODE FOR TRAIL_DATASET_4.CSV\n",
    "# ============================================\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('trail_dataset_4.csv')\n",
    "\n",
    "print(\"STARTING DATA CLEANING PROCESS...\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Step 1: Convert date columns to datetime (correct column names)\n",
    "print(\"\\nStep 1: Converting date columns to datetime...\")\n",
    "date_cols = ['screening_date', 'enrollment_date', 'randomization_date']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"Converted {col} to datetime\")\n",
    "\n",
    "# Step 2: Convert boolean columns to proper boolean type\n",
    "print(\"\\nStep 2: Converting boolean columns...\")\n",
    "bool_cols = ['has_diabetes', 'has_hypertension', 'has_heart_disease']\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(bool)\n",
    "        print(f\"Converted {col} to boolean\")\n",
    "\n",
    "# Step 3: Remove duplicate rows\n",
    "print(\"\\nStep 3: Removing duplicates...\")\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df)\n",
    "print(f\"Removed {duplicates_removed} duplicate rows\")\n",
    "\n",
    "# Step 4: Handle missing values in numeric columns (use correct column names)\n",
    "print(\"\\nStep 4: Handling missing values in numeric columns...\")\n",
    "numeric_cols = ['weight_kg', 'height_cm', 'bmi', 'systolic_bp', 'diastolic_bp',\n",
    "                'hemoglobin_gdl', 'creatinine_mgdl', 'glucose_mgdl',\n",
    "                'medication_adherence', 'visit_completion_rate']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        missing_before = df[col].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            median_val = df[col].median()\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "            print(f\"Imputed {missing_before} missing values in {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# Step 5: Handle missing values in categorical columns\n",
    "print(\"\\nStep 5: Handling missing values in categorical columns...\")\n",
    "categorical_cols = ['gender', 'ethnicity', 'country', 'site_id', 'city']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_before = df[col].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            mode_val = df[col].mode()\n",
    "            fill_val = mode_val[0] if not mode_val.empty else 'Unknown'\n",
    "            df[col] = df[col].fillna(fill_val)\n",
    "            print(f\"Imputed {missing_before} missing values in {col} with mode: {fill_val}\")\n",
    "\n",
    "# Step 6: Filter out invalid outliers\n",
    "print(\"\\nStep 6: Removing invalid outliers...\")\n",
    "initial_rows = len(df)\n",
    "\n",
    "# Age filter (18-85 years)\n",
    "if 'age' in df.columns:\n",
    "    df = df[(df['age'] >= 18) & (df['age'] <= 85)]\n",
    "\n",
    "# Blood pressure filters\n",
    "if 'systolic_bp' in df.columns:\n",
    "    df = df[(df['systolic_bp'] >= 90) & (df['systolic_bp'] <= 200)]\n",
    "\n",
    "if 'diastolic_bp' in df.columns:\n",
    "    df = df[(df['diastolic_bp'] >= 60) & (df['diastolic_bp'] <= 120)]\n",
    "\n",
    "# Glucose filter (remove negative values and extreme highs)\n",
    "if 'glucose_mgdl' in df.columns:\n",
    "    df = df[(df['glucose_mgdl'] >= 70) & (df['glucose_mgdl'] <= 300)]\n",
    "\n",
    "outliers_removed = initial_rows - len(df)\n",
    "print(f\"Removed {outliers_removed} rows with invalid outliers\")\n",
    "\n",
    "# Step 7: Recalculate BMI and fix inconsistencies\n",
    "print(\"\\nStep 7: Recalculating BMI for consistency...\")\n",
    "if 'weight_kg' in df.columns and 'height_cm' in df.columns and 'bmi' in df.columns:\n",
    "    df['height_m'] = df['height_cm'] / 100\n",
    "    df['calculated_bmi'] = df['weight_kg'] / (df['height_m'] ** 2)\n",
    "    \n",
    "    bmi_diff_mask = (df['bmi'] - df['calculated_bmi']).abs() > 3\n",
    "    inconsistent_bmis = bmi_diff_mask.sum()\n",
    "    \n",
    "    df.loc[bmi_diff_mask, 'bmi'] = df.loc[bmi_diff_mask, 'calculated_bmi']\n",
    "    df.drop(columns=['height_m', 'calculated_bmi'], inplace=True)\n",
    "    print(f\"Fixed {inconsistent_bmis} inconsistent BMI values\")\n",
    "\n",
    "# Step 8: Final data validation\n",
    "print(\"\\nStep 8: Final data validation...\")\n",
    "missing_final = df.isnull().sum()\n",
    "total_missing = missing_final.sum()\n",
    "print(f\"Total missing values after cleaning: {total_missing}\")\n",
    "\n",
    "# Step 9: Save cleaned dataset\n",
    "output_filename = 'trail_dataset_4_cleaned.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Cleaned dataset shape: {df.shape}\")\n",
    "print(f\"Cleaned dataset saved as: {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
